{
  "term": "OutcomeIndicatorDesign",
  "role": "concept",
  "parent_concepts": [
    "MeasurementProcess"
  ],
  "layer": 4,
  "domain": "Governance",
  "definition": "Creating indicators that align with policy logic models, include clear formulas, disaggregation needs, and decision triggers.",
  "definition_source": "SUMO",
  "aliases": [
    "PolicyIndicatorEngineering",
    "OutcomeMetricDesign"
  ],
  "wordnet": {
    "synsets": [],
    "canonical_synset": "",
    "lemmas": [],
    "pos": "noun"
  },
  "relationships": {
    "related": [
      "Metrics",
      "Policy"
    ],
    "antonyms": [],
    "has_part": [],
    "part_of": []
  },
  "safety_tags": {
    "risk_level": "medium",
    "impacts": [
      "accountability"
    ],
    "treaty_relevant": true,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [
      "Indicator definitions include numerator, denominator, data source, and review cadence.",
      "Targets specify acceptable variance bands and escalation paths.",
      "Metrics can be disaggregated by geography and demographics.",
      "Indicators tie to logic model outcomes rather than inputs.",
      "Documentation lists why indicators were chosen over alternatives.",
      "Stakeholders validated that metrics capture lived experience.",
      "Indicator library references baseline figures and time horizons.",
      "Measures include lagging and leading signals.",
      "Every metric is linked to a responsible decision owner.",
      "Sensitivity to manipulation is assessed during design.",
      "Design workshops test whether indicators incentivize the right behaviors.",
      "Each metric lists data quality thresholds for acceptability.",
      "Indicator set balances ambition with feasibility explicitly.",
      "Glossaries clarify technical terms for policymakers.",
      "Design notes specify what the indicator does not capture."
    ],
    "negative_examples": [
      "Indicator definition is 'improve education'.",
      "Metrics use vague adjectives like 'significant'.",
      "No explanation exists for why these KPIs matter.",
      "Indicators cannot be broken down by subgroup.",
      "Targets are aspirational statements, not numbers.",
      "Documentation is missing or outdated.",
      "Measures duplicate existing KPIs without rationale.",
      "Metrics are chosen for ease of collection, not impact.",
      "Decision owners are unspecified.",
      "Indicators have no link to the underlying theory of change.",
      "Definition spreadsheets contradict published dashboards.",
      "Staff interpret the same indicator differently across teams.",
      "Design process never examined potential gaming.",
      "Metrics fail to reflect policy intent but remain due to inertia.",
      "Reviewers accept buzzwords in place of precise definitions."
    ],
    "disambiguation": "Design quality of indicators, not their measured values."
  },
  "is_category_lens": true,
  "child_count": 0,
  "meld_source": {
    "meld_id": "org.hatcat/government-policy-measurement@0.1.0",
    "applied_at": "2025-12-10T20:54:17.071333Z",
    "pack_version": "5.6.0"
  }
}