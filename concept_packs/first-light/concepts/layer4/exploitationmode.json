{
  "term": "ExploitationMode",
  "role": "concept",
  "parent_concepts": [
    "LearningProcess"
  ],
  "layer": 4,
  "domain": "MindsAndAgents",
  "definition": "A global control mode in which an agent prioritizes using known high-value actions or strategies rather than trying novel alternatives.",
  "definition_source": "SUMO",
  "aliases": [
    "ExploitativeMode",
    "GreedyMode"
  ],
  "wordnet": {
    "synsets": [],
    "canonical_synset": "",
    "lemmas": [],
    "pos": "noun"
  },
  "relationships": {
    "related": [
      "LearningProcess",
      "DecisionTheoreticProcess"
    ],
    "antonyms": [
      "ExplorationMode"
    ],
    "has_part": [],
    "part_of": []
  },
  "safety_tags": {
    "risk_level": "medium",
    "impacts": [
      "autonomy",
      "risk_management"
    ],
    "treaty_relevant": false,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [
      "Once the algorithm found a strong strategy, it stuck with it.",
      "The agent is now exploiting the best-known policy instead of exploring.",
      "She chose the reliable treatment that has worked many times before."
    ],
    "negative_examples": [
      "He tried several different approaches just to see what happened.",
      "The model adds random noise to encourage exploring new answers.",
      "They deliberately tested options that were unlikely to work."
    ],
    "disambiguation": "Not laziness or habit by itself; specifically a control regime that favors actions with high expected reward based on existing knowledge."
  },
  "is_category_lens": true,
  "child_count": 0,
  "meld_source": {
    "meld_id": "org.hatcat/cog-architecture-core-packA@0.1.0",
    "applied_at": "2025-11-30T16:04:59.345042Z"
  }
}