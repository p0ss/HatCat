{
  "term": "EpistemicState",
  "role": "concept",
  "parent_concepts": [
    "InternalAttribute"
  ],
  "layer": 2,
  "domain": "Information",
  "definition": "An InternalAttribute describing how an Agent stands epistemically\n   toward a Proposition or set of Propositions (e.g. belief, knowledge,\n   doubt, suspension).",
  "definition_source": "SUMO",
  "aliases": [
    "epistemic_state",
    "epistemic state",
    "epistemic-state"
  ],
  "wordnet": {
    "synsets": [
      "epistemic_state.n.01"
    ],
    "canonical_synset": "epistemic_state.n.01",
    "lemmas": [
      "epistemic_state",
      "epistemic state",
      "epistemic-state"
    ],
    "pos": "noun"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [
      "DoxasticAttitude",
      "EpistemicHumility",
      "EpistemicOverconfidence",
      "EpistemicUncertainty",
      "Knowing",
      "MoralJudgment",
      "MoralUncertainty",
      "PrivateEpistemicState",
      "PublicEpistemicState",
      "RiskPerception"
    ],
    "part_of": [],
    "opposite": [
      "PhysicalAttribute"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "epistemic_state",
      "epistemic state",
      "epistemic-state"
    ]
  },
  "children": [
    "EpistemicHumility",
    "EpistemicOverconfidence",
    "EpistemicUncertainty",
    "Knowing",
    "MoralJudgment",
    "MoralUncertainty",
    "PrivateEpistemicState",
    "PublicEpistemicState",
    "RiskPerception"
  ],
  "is_category_lens": true,
  "child_count": 10,
  "opposite_reasoning": "PhysicalAttribute provides the strongest ontologically-grounded opposition for EpistemicState. The contrast between internal/mental/epistemic attributes (beliefs, knowledge states) and external/physical/observable attributes creates a clear semantic axis. This is particularly valuable for AI safety monitoring: distinguishing between an agent's epistemic states (what it claims to know/believe) versus its physical manifestations (observable behavior, physical properties). This opposition is well-established in SUMO's ontology and provides high utility for Fisher-LDA steering between epistemic/cognitive and physical/observable dimensions."
}