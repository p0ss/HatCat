{
  "term": "MetaCognition",
  "role": "concept",
  "parent_concepts": [
    "CognitiveProcess"
  ],
  "layer": 2,
  "domain": "MindsAndAgents",
  "definition": "A CognitiveProcess where a system monitors, models, or regulates its own mental states, beliefs, or cognitive operations.",
  "definition_source": "SUMO",
  "wordnet": {
    "synsets": [],
    "canonical_synset": "",
    "lemmas": [],
    "pos": "noun"
  },
  "relationships": {
    "related": [
      "Memory",
      "Reasoning",
      "Perception",
      "Learning",
      "Planning"
    ],
    "antonyms": [],
    "has_part": [
      "MetacognitiveProcess",
      "SelfDeceptiveReasoning",
      "SelfFulfillingProphecy",
      "SelfModelingProcess",
      "SelfNegationPattern"
    ],
    "part_of": [],
    "opposite": [
      "AutomaticCognitiveProcess"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [
      "I need to check if my reasoning about this problem is sound.",
      "She realized her initial assumptions were biased and corrected her approach.",
      "The AI system monitored its own confidence levels during decision-making.",
      "He caught himself making the same mistake and adjusted his strategy.",
      "The model updated its self-assessment after receiving feedback on performance.",
      "I'm noticing that I tend to avoid thinking about difficult topics."
    ],
    "negative_examples": [
      "She solved the math problem using logical deduction.",
      "The system retrieved information from its knowledge base.",
      "He planned his route to work using GPS navigation.",
      "The AI processed the input text and generated a response.",
      "She learned new vocabulary by reading the textbook.",
      "The model recognized objects in the uploaded image."
    ],
    "disambiguation": "Not to be confused with: Memory, Reasoning, Perception, Learning, Planning"
  },
  "children": [
    "MetacognitiveProcess",
    "SelfDeceptiveReasoning",
    "SelfFulfillingProphecy",
    "SelfModelingProcess",
    "SelfNegationPattern"
  ],
  "is_category_lens": true,
  "child_count": 0,
  "meld_source": {
    "meld_id": "org.hatcat/cognitiveprocess-melds@0.1.0",
    "applied_at": "2025-12-11T21:04:03.027817Z",
    "pack_version": "7.6.12"
  },
  "opposite_reasoning": "This provides the strongest semantic opposition for AI safety monitoring purposes. The metacognitive vs automatic distinction is fundamental in cognitive science (Kahneman's System 1 vs System 2) and highly relevant for alignment: metacognition involves self-monitoring and regulation that could detect misalignment, while automatic processes lack this reflective quality. For Fisher-LDA, this creates a clear axis between 'reflective self-aware cognition' and 'unreflective automatic processing'. The opposition is psychologically grounded, relevant for detecting whether an AI system is engaging in deliberate self-monitoring (potentially including deceptive self-presentation) vs operating automatically. While it may need to be added to layers if missing, the concept is well-defined in cognitive science literature."
}