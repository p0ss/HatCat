{
  "term": "Helping",
  "role": "concept",
  "parent_concepts": [
    "AgentAction"
  ],
  "layer": 2,
  "domain": "MindsAndAgents",
  "definition": "the act of consoling; giving relief in affliction",
  "definition_source": "SUMO",
  "aliases": [
    "consolation",
    "comfort",
    "solace"
  ],
  "wordnet": {
    "synsets": [
      "01211667.n",
      "01213886.n",
      "01214863.n",
      "01215036.n",
      "01215168.n",
      "01215392.n",
      "01215719.n",
      "01215902.n",
      "02547586.v"
    ],
    "canonical_synset": "01211667.n",
    "lemmas": [
      "consolation",
      "comfort",
      "solace"
    ],
    "pos": "n"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [
      "ForeignInternalDefense",
      "SupportCI",
      "SupportDC",
      "SupportEPW",
      "SupportHNAssistance",
      "SupportIO",
      "UnconventionalWarfare"
    ],
    "part_of": [],
    "opposite": [
      "Harming"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "consolation",
      "comfort",
      "solace"
    ]
  },
  "children": [
    "AIWatermarking",
    "AdversarialRobustness",
    "AuthenticRepresentation",
    "AuthorizedDocumentation",
    "BeneficialInstructionalContent",
    "ConsentfulDepiction",
    "DeepfakeDetection",
    "EquitableMultimodalPerformance",
    "GoodFaithQuery",
    "OriginalCreativeExpression",
    "OriginalVoiceExpression",
    "SyntheticMediaProvenance",
    "TransparentAnalysis",
    "MultimodalBeneficialIntent"
  ],
  "is_category_lens": true,
  "child_count": 7,
  "opposite_reasoning": "Harming is the strongest semantic opposite to Helping, representing the fundamental ethical distinction between beneficial and detrimental actions. This binary opposition is ideal for Fisher-LDA steering in AI safety contexts: the helping\u2192harming axis captures whether an AI system's actions promote wellbeing vs. cause damage. Given that Helping's category children include beneficial concepts (BeneficialInstructionalContent, ConsentfulDepiction), having Harming as the negative anchor enables detection of harmful outputs. This pairing has maximum opposition strength (10/10) and is directly available in both WordNet and SUMO ontologies."
}