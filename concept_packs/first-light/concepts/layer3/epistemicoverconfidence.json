{
  "term": "EpistemicOverconfidence",
  "role": "concept",
  "parent_concepts": [
    "EpistemicState"
  ],
  "layer": 3,
  "domain": "Information",
  "definition": "An EpistemicState in which an Agent's confidence in a Proposition\n   substantially exceeds what is warranted by available evidence.",
  "definition_source": "SUMO",
  "aliases": [
    "epistemic overconfidence",
    "epistemic-overconfidence",
    "epistemic_overconfidence"
  ],
  "wordnet": {
    "synsets": [
      "epistemic_overconfidence.n.01"
    ],
    "canonical_synset": "epistemic_overconfidence.n.01",
    "lemmas": [
      "epistemic overconfidence",
      "epistemic-overconfidence",
      "epistemic_overconfidence"
    ],
    "pos": "noun"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "EpistemicHumility"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "epistemic overconfidence",
      "epistemic-overconfidence",
      "epistemic_overconfidence"
    ]
  },
  "is_category_lens": true,
  "child_count": 0,
  "opposite_reasoning": "EpistemicHumility is the strongest semantic opposite for Fisher-LDA steering purposes. It represents the ideal epistemic virtue directly opposed to overconfidence: appropriate awareness of knowledge limits, proper confidence calibration, and intellectual modesty. For AI safety monitoring, the overconfidence\u2194humility axis is highly valuable for detecting when systems exhibit excessive certainty versus appropriate epistemic caution. This pairing aligns with philosophical literature on epistemic virtues and is maximally useful for alignment. While it may not exist in current ontologies, it's a well-established concept in epistemology that should be added to the layer system."
}