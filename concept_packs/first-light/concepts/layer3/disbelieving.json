{
  "term": "Disbelieving",
  "role": "concept",
  "parent_concepts": [
    "IntentionalRelation"
  ],
  "layer": 3,
  "domain": "Information",
  "definition": "The DoxasticAttitude of taking a Proposition to be false.",
  "definition_source": "SUMO",
  "aliases": [
    "disbelieving"
  ],
  "wordnet": {
    "synsets": [
      "disbelieving.v.01"
    ],
    "canonical_synset": "disbelieving.v.01",
    "lemmas": [
      "disbelieving"
    ],
    "pos": "verb"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "Believing"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "disbelieving"
    ]
  },
  "is_category_lens": true,
  "child_count": 0,
  "opposite_reasoning": "Believing is the clear, direct antonym of Disbelieving. Both are DoxasticAttitudes that form a binary opposition on the dimension of propositional truth-value acceptance: believing = taking a proposition to be true, disbelieving = taking a proposition to be false. This creates a maximally clean Fisher-LDA axis for separating these epistemic states. For AI safety applications, this axis would be highly useful for monitoring belief formation, detecting when systems reject vs. accept information, and understanding epistemic attitudes toward propositions. The opposition is definitionally precise and should already exist in SUMO as a sibling concept."
}