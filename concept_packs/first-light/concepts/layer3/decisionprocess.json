{
  "term": "DecisionProcess",
  "role": "concept",
  "parent_concepts": [
    "CorporateAICognition"
  ],
  "layer": 3,
  "domain": "MindsAndAgents",
  "definition": "A CognitiveProcess that selects actions or policies among options\n   given Goals, beliefs, values, and constraints.",
  "definition_source": "SUMO",
  "aliases": [
    "decision_process",
    "decision process",
    "decision-process"
  ],
  "wordnet": {
    "synsets": [
      "decision_process.v.01"
    ],
    "canonical_synset": "decision_process.v.01",
    "lemmas": [
      "decision_process",
      "decision process",
      "decision-process"
    ],
    "pos": "verb"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "AutomaticProcess"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "decision_process",
      "decision process",
      "decision-process"
    ]
  },
  "is_category_lens": true,
  "child_count": 0,
  "opposite_reasoning": "AutomaticProcess provides the strongest complementary opposition to DecisionProcess along the dimension most relevant for AI safety and alignment: deliberate, conscious, goal-directed selection vs. automatic, non-deliberative execution. This distinction is crucial for understanding when an AI system is engaging in strategic planning vs. executing learned patterns. The controlled/automatic processing distinction is well-established in cognitive science and highly relevant for Fisher-LDA separation. For AI safety monitoring, distinguishing deliberate decision-making from automatic responses helps identify when systems are in 'thinking' vs 'reactive' modes, which is relevant for deception detection and alignment verification."
}