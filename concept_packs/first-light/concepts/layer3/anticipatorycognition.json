{
  "term": "AnticipatoryCognition",
  "role": "concept",
  "parent_concepts": [
    "FutureCognition"
  ],
  "layer": 3,
  "domain": "MindsAndAgents",
  "definition": "Reasoning where current actions are chosen because of predicted\n  future states, including opportunity shaping and risk avoidance.",
  "definition_source": "SUMO",
  "wordnet": {
    "synsets": [],
    "canonical_synset": "",
    "lemmas": [],
    "pos": ""
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [
      "EarlyWarningAnalysis",
      "FutureSeedingAction",
      "StrategicPrepositioning"
    ],
    "part_of": [],
    "opposite": [
      "ReactiveCognition"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": ""
  },
  "children": [
    "EarlyWarningAnalysis",
    "FutureSeedingAction",
    "StrategicPrepositioning"
  ],
  "is_category_lens": true,
  "child_count": 3,
  "opposite_reasoning": "ReactiveCognition provides the strongest semantic opposition for AI safety applications. The anticipatory-reactive axis is critical for monitoring whether AI systems engage in forward planning (potentially deceptive preparation, strategic positioning) versus immediate stimulus-response behavior. This maps well to the category children (EarlyWarningAnalysis, FutureSeedingAction, StrategicPrepositioning) which all involve proactive future-oriented behavior. For Fisher-LDA, this creates a clear axis distinguishing planning/preparation behaviors from reactive responses. While it doesn't exist in standard ontologies, it's a theoretically sound and practically useful opposition worth adding."
}