{
  "term": "AgentAction",
  "role": "concept",
  "parent_concepts": [
    "MindsAndAgents"
  ],
  "layer": 1,
  "definition": "Grouping category for UserAction, Maneuver, BodyMotion...",
  "wordnet": {
    "synsets": [],
    "canonical_synset": "",
    "lemmas": [],
    "pos": ""
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "InternalChange"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": ""
  },
  "children": [
    "UserAction",
    "Maneuver",
    "BodyMotion",
    "Translocation",
    "PhysicalActions",
    "CreativeActivities",
    "Communication",
    "Deception",
    "ServiceProcess",
    "Helping",
    "ChangeOfPossession",
    "Pretending"
  ],
  "is_category_lens": false,
  "child_count": 0,
  "opposite_reasoning": "InternalChange provides the strongest opposition for Fisher-LDA steering in AI safety contexts. AgentAction represents externally observable, intentional behaviors (the primary concern for AI alignment - what the AI does). InternalChange represents internal, often automatic processes. This distinction is crucial for: (1) Differentiating between internal states and external actions in AI systems, (2) Understanding when models are planning/acting vs passively processing, (3) Deception detection (internal intent vs external behavior). The external/internal distinction is more semantically rich than the general Process/Object divide, and more concrete than abstract state concepts. While InternalChange may need verification in SUMO, it represents a natural complement within the Process hierarchy."
}